{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this task was to use crime data from Chicago's Data Portal (Crimes - 2001 to present.csv) to train a supervised learning model that could predict the occurrence of a crime in Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEFT                                289054\n",
      "BATTERY                              250844\n",
      "CRIMINAL DAMAGE                      156058\n",
      "NARCOTICS                            143367\n",
      "ASSAULT                               85091\n",
      "OTHER OFFENSE                         84997\n",
      "BURGLARY                              78550\n",
      "MOTOR VEHICLE THEFT                   63719\n",
      "DECEPTIVE PRACTICE                    54282\n",
      "ROBBERY                               51717\n",
      "CRIMINAL TRESPASS                     39092\n",
      "WEAPONS VIOLATION                     14668\n",
      "PROSTITUTION                          13758\n",
      "PUBLIC PEACE VIOLATION                 9574\n",
      "OFFENSE INVOLVING CHILDREN             9375\n",
      "CRIM SEXUAL ASSAULT                    5585\n",
      "SEX OFFENSE                            5216\n",
      "INTERFERENCE WITH PUBLIC OFFICER       3207\n",
      "GAMBLING                               2915\n",
      "LIQUOR LAW VIOLATION                   2788\n",
      "ARSON                                  2237\n",
      "HOMICIDE                               1954\n",
      "KIDNAPPING                             1342\n",
      "INTIMIDATION                            843\n",
      "STALKING                                701\n",
      "OBSCENITY                               108\n",
      "CONCEALED CARRY LICENSE VIOLATION        80\n",
      "PUBLIC INDECENCY                         35\n",
      "NON-CRIMINAL                             32\n",
      "OTHER NARCOTIC VIOLATION                 23\n",
      "HUMAN TRAFFICKING                        13\n",
      "RITUALISM                                11\n",
      "NON - CRIMINAL                            9\n",
      "NON-CRIMINAL (SUBJECT SPECIFIED)          1\n",
      "DOMESTIC VIOLENCE                         1\n",
      "Name: Primary_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# The data to load\n",
    "f = \"crime_data/Crimes_-_2001_to_present.csv\"\n",
    "\n",
    "# Code to load random sample of .csv\n",
    "num_lines = sum(1 for l in open(f))\n",
    "# Sample size - in this case ~20% - Anymore than this I run into memory issues\n",
    "size = int(num_lines / 5)\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
    "\n",
    "# Read the data\n",
    "## According to Chicago Data Portal, 'Community Areas' is current.\n",
    "## I am going to remove 'Community Area'.\n",
    "drops = ['Case Number', 'Block',  'Description',  'Location Description',\n",
    "                    'Updated On', 'Community Area']\n",
    "data = pd.read_csv(f, skiprows=skip_idx).drop(drops, axis=1)\n",
    "data.columns = ['ID','Date','IUCR',\n",
    "                     'Primary_Type','Arrest','Domestic', 'Beat', 'District',\n",
    "                     'Ward', 'FBI_Code', 'X_Coordinate', 'Y_Coordinate',\n",
    "                     'Year', 'Latitude', 'Longitude', 'Location',\n",
    "                     'Historical_Wards', 'Zip Codes', 'Community_Areas',\n",
    "                     'Census_Tracts', 'Wards', 'Boundaries_ZIP',\n",
    "                     'Police_Dist', 'Police_Beats']\n",
    "print(data['Primary_Type'].value_counts())\n",
    "BURGLARY = data[data.Primary_Type == 'BURGLARY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is part of the **eda.py** program. This program limits the crime data (Crimes_-_2001_to_present.csv) to just a random 20% sample of the original rows. Working with any larger of a sample resulted in memory issues. \n",
    "The next step was to get a sense of the types of crimes contained in these data. By looking at the \"Primary Type\" column I could see a standardized description of the type of crime each observation in the data represents. The data contain a wide array of offenses. To build a model that could predict every type of crime would require many different features. Thus, I felt it was appropriate to limit this exercise to just looking at one type of crime. I chose Burglary since it is a common offense in Chicago, and I felt I could develop an appropriate set of model features for predicting this type of crime.\n",
    "These sample data were then limited to just burglaries and output to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to Predict Burglary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program **burglaries_predictor_variables.py** takes the dataset described in the last step and adds some columns that will be used as features for our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Time Related Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each observation, how much time has elapsed since the last burglary in the same community area (in days)\n",
    "* Dummy variable to indicate working hours of the day (8am - 7pm)\n",
    "* Dummy variable to indicate colder (winter) months (October to March)\n",
    "* Dummy variable to indicate work days of the week (M - F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Geographical Features (Community Area Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average amount of time that elapses between burglaries within a community area (in days)\n",
    "* Dummy variables to indicate each community area\n",
    "* Total number of burglaries in that community area\n",
    "* Number of affordable housing units within that community area\n",
    "    * The data on affordable housing units by community area were obtained from here: https://data.cityofchicago.org/Community-Economic-Development/Affordable-Housing-Units-by-Community-Area/yvj4-y3fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Law Enforcement Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of police beats (from crimes dataset)\n",
    "* Haversine  distance to nearest police station (in kilometers)\n",
    "    * The latitude and longitude for police station locations in Chicago were obtained from: https://data.cityofchicago.org/Public-Safety/Police-Stations/z8bn-74gv\n",
    "    * Haversine distances were calculated from each burglary to each police station. Then for each burglary, the minimum of the distances calculated were used as the distance to the nearest police station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics of Training Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of the feature variables are described below. For the sake of space, only 2 of the 77 community variable dummies are displayed on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>working_hours</th>\n",
       "      <th>winter</th>\n",
       "      <th>work_day</th>\n",
       "      <th>10.0_area</th>\n",
       "      <th>11.0_area</th>\n",
       "      <th>CA_AVG_DELTA</th>\n",
       "      <th>CA_COUNT</th>\n",
       "      <th>LI_COUNT</th>\n",
       "      <th>police</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.00000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "      <td>77543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.580426</td>\n",
       "      <td>0.479076</td>\n",
       "      <td>0.234283</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>6.591533</td>\n",
       "      <td>1612.864643</td>\n",
       "      <td>5.528352</td>\n",
       "      <td>157.484712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493492</td>\n",
       "      <td>0.499565</td>\n",
       "      <td>0.423553</td>\n",
       "      <td>0.12211</td>\n",
       "      <td>0.069189</td>\n",
       "      <td>6.602893</td>\n",
       "      <td>901.593887</td>\n",
       "      <td>7.953746</td>\n",
       "      <td>80.783302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.997870</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.946607</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333036</td>\n",
       "      <td>1541.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.217308</td>\n",
       "      <td>2267.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.264371</td>\n",
       "      <td>3341.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>277.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       working_hours        winter      work_day    10.0_area     11.0_area  \\\n",
       "count   77543.000000  77543.000000  77543.000000  77543.00000  77543.000000   \n",
       "mean        0.580426      0.479076      0.234283      0.01514      0.004810   \n",
       "std         0.493492      0.499565      0.423553      0.12211      0.069189   \n",
       "min         0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%         1.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%         1.000000      1.000000      0.000000      0.00000      0.000000   \n",
       "max         1.000000      1.000000      1.000000      1.00000      1.000000   \n",
       "\n",
       "       CA_AVG_DELTA      CA_COUNT      LI_COUNT        police  \n",
       "count  77543.000000  77543.000000  77543.000000  77543.000000  \n",
       "mean       6.591533   1612.864643      5.528352    157.484712  \n",
       "std        6.602893    901.593887      7.953746     80.783302  \n",
       "min        1.997870     65.000000      0.000000      1.000000  \n",
       "25%        2.946607    808.000000      1.000000     89.000000  \n",
       "50%        4.333036   1541.000000      2.000000    174.000000  \n",
       "75%        8.217308   2267.000000      6.000000    227.000000  \n",
       "max       97.264371   3341.000000     33.000000    277.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"training_data_burglary.csv\")\n",
    "data.iloc[:,np.r_[32:37,111:115]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to build a model that could predict the occurrence of a burglary within a certain future timeframe. More specifically I wanted to identify whether a burglary will happen in a community area within the next two weeks. The outcome variable is a binary outcome, taking on 1 if a burglary happened within 14 days of the last burglary in the community area, or 0 otherwise. Since the outcome is categorical, I would need to use a classifier algorithm. I chose to use a random forest model for several reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first reason I chose to use a random forest model was that it is easy to optimize the feature selection of the model. My approach, as shown below, would be to first run the random forest classifier with all the features I described in the previous section, score the algorithm, identify the most important features, then repeat the same classification algorithm using only the most important features, with gini-importance above a certain threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second reason I chose to use a random forest is that it resolves the issues of using a \"greedy algorithm\", like with implementing a decision tree, as we are using many decision trees to prevent our results from being biased by one decision tree outcome. In addition to this we are not susceptible to overfitting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model With All Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859889399968991\n",
      "          Predict No  Predict Yes\n",
      "True No          354         1841\n",
      "True Yes         365        16789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 90\n",
    "#\n",
    "data = pd.read_csv(\"training_data_burglary.csv\")\n",
    "Training_Target = np.where((data['day_delta'] < 14), 1, 0)\n",
    "Training_Data = data.iloc[:,np.r_[32:115]]\n",
    "\n",
    "data_training, data_test, target_training, target_test = \\\n",
    "    train_test_split(Training_Data, Training_Target, test_size = 0.25, random_state=1)\n",
    "random_forest_machine = RandomForestClassifier(n_estimators=n)\n",
    "random_forest_machine.fit(data_training, target_training)\n",
    "predictions = random_forest_machine.predict(data_test)\n",
    "print(accuracy_score(target_test, predictions))\n",
    "\n",
    "cm = confusion_matrix(target_test,predictions)\n",
    "confusion_matrix = pd.DataFrame(\n",
    "\tcm,\n",
    "\tcolumns = ['Predict No', 'Predict Yes'],\n",
    "\tindex = ['True No', 'True Yes']\n",
    ")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model scored ~0.88598. As we can see with the model with all features, our random forest algorithm correctly predicted the occurrence of a burglary 16,788 times and failed to predict a burglary only 340 times. However, when burglaries didn't happen it tended to make a type I error and predict a burglary would be present, when in fact a burglary did not occur within the 14 day timespan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the feature importance of all the variables used in the first model shows that a lot of the features weren't contributing much to the decision-making process for our algorithm. At first glance only a small number of features such as average time between burglaries (*CA_AVG_DELTA*) have a relatively high importance. The steps below will describe what was done to limit to only important features of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_AVG_DELTA    1\n",
      "CA_COUNT        1\n",
      "police          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train Model to Select Most Important Features and Refine The Model\n",
    "# Fine Best Features\n",
    "select_features = SelectFromModel(random_forest_machine, threshold = 0.1)\n",
    "select_features.fit(data_training, target_training)\n",
    "x_refined_train = select_features.transform(data_training)\n",
    "x_refined_test = select_features.transform(data_test)\n",
    "\n",
    "# Print Top Features\n",
    "important_features = select_features.get_support()\n",
    "feature_name = Training_Data.columns[important_features]\n",
    "print(feature_name.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code does the following:\n",
    "1) SelectFromModel detects the features of our previous model that have a feature importance above 0.1\n",
    "2) The training and test data are then transformed to only take the features of the required importance\n",
    "3) Print a list of the top features\n",
    "    * Police Beat Count\n",
    "    * Community Burglary Count\n",
    "    * Community Average Time Between Burglaries\n",
    "\n",
    "Below we will re-run the random forest classifier with only these three features.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8917256705772908\n",
      "          Predict No  Predict Yes\n",
      "True No          399         1796\n",
      "True Yes         299        16855\n"
     ]
    }
   ],
   "source": [
    "#Train and Test New Model\n",
    "refined_forest_machine = RandomForestClassifier(n_estimators=n)\n",
    "refined_forest_machine.fit(x_refined_train, target_training)\n",
    "refined_predictions = refined_forest_machine.predict(x_refined_test)\n",
    "print(accuracy_score(target_test, refined_predictions))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cmr = confusion_matrix(target_test,refined_predictions)\n",
    "confusion_matrix = pd.DataFrame(\n",
    "\tcmr,\n",
    "\tcolumns = ['Predict No', 'Predict Yes'],\n",
    "\tindex = ['True No', 'True Yes'])\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for the refined model improved marginally to ~0.89172. The confusion matrix however indicates the model became better at predicting burglaries when they actually happened, but would still overpredict a burglary happening when it did not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
